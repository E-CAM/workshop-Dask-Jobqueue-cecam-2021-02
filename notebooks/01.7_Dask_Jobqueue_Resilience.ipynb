{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask jobqueue example\n",
    "\n",
    "## What is Dask jobqueue? (<https://jobqueue.dask.org/>)\n",
    "\n",
    "* deploys Dask workers on typical HPC job queueing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo estimate with multiple Dask batch job workers\n",
    "\n",
    "We define a Dask jobqueue cluster with Dask workers that each have 8 CPUs and 48 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.distributed\n",
    "import dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x151d8ea44160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "\n",
    "    # Dask worker size\n",
    "    cores=8, memory='48GB',\n",
    "    processes=1, # Dask workers per job\n",
    "    \n",
    "    # SLURM job script things\n",
    "    queue='cluster', walltime='00:15:00',\n",
    "    \n",
    "    # Dask worker network and temporary storage\n",
    "    interface='ib0', local_directory='$TMPDIR',\n",
    ")\n",
    "\n",
    "client = dask.distributed.Client(cluster)\n",
    "cluster.adapt(minimum=16, maximum=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.11:38827</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.11:8787/status' target='_blank'>http://172.18.4.11:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.11:38827' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here everything is (almost) the same\n",
    "\n",
    "We'll return the Dask array for `pi` and handle computation more explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, dask.array\n",
    "\n",
    "def calculate_pi(size_in_bytes, number_of_chunks):\n",
    "    \n",
    "    \"\"\"Calculate pi using a Monte Carlo method.\"\"\"\n",
    "    \n",
    "    array_shape = (int(size_in_bytes / 8 / 2), 2)\n",
    "    chunk_size = (int(array_shape[0] / number_of_chunks), 2)\n",
    "    \n",
    "    # 2D random positions array using dask.array\n",
    "    xy = dask.array.random.uniform(\n",
    "        low=0.0, high=1.0, size=array_shape,\n",
    "        # specify chunk size, i.e. task number\n",
    "        chunks=chunk_size )\n",
    "  \n",
    "    xy_inside_circle = (xy ** 2).sum(axis=1) < 1 # boolean\n",
    "\n",
    "    pi = 4 * xy_inside_circle.sum() / xy_inside_circle.size\n",
    "        \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again...\n",
    "\n",
    "Note the `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 341 ms, sys: 52.8 ms, total: 394 ms\n",
      "Wall time: 786 ms\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100).compute() # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 816 ms, sys: 44.8 ms, total: 861 ms\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=250).compute() # 100 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way for handling computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: finalize-c6ccfe955bda2fb4210039cdebc6dafd>\n",
      "3.14158823232\n"
     ]
    }
   ],
   "source": [
    "pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=250)\n",
    "pi = client.compute(\n",
    "    pi\n",
    ")\n",
    "print(pi)\n",
    "print(pi.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if a worker dies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll find out all \"our\" job ids, mark a few of them non-preemptible, filter for the preemptible jobs, and define a function to kill one randomly selected preemptible job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_jobs():\n",
    "    current_jobs = !squeue | grep R | grep $USER | grep dask | awk '{print $1}'\n",
    "    return current_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['47918', '47919', '47920', '47921', '47922', '47923', '47924', '47925']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_preemptible_jobs = get_current_jobs()[:8]\n",
    "non_preemptible_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preemptible_jobs():\n",
    "    return list(filter(lambda j: j not in non_preemptible_jobs, get_current_jobs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['47926', '47927', '47928', '47929', '47930', '47931', '47932', '47933']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_preemptible_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def kill_random_preemptible_job():\n",
    "    preemptible_jobs = get_preemptible_jobs()\n",
    "    if preemptible_jobs:\n",
    "        worker_to_kill = random.choice(preemptible_jobs)\n",
    "        print(f\"will cancel job {worker_to_kill}\")\n",
    "        !scancel {worker_to_kill}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['47926', '47927', '47928', '47929', '47930', '47931', '47932', '47933']\n",
      "will cancel job 47932\n",
      "['47926', '47927', '47928', '47929', '47930', '47931', '47933']\n"
     ]
    }
   ],
   "source": [
    "print(get_preemptible_jobs())\n",
    "kill_random_preemptible_job()\n",
    "sleep(1)\n",
    "print(get_preemptible_jobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             47934   cluster dask-wor smomw122 PD       0:00      1 (Priority) \n",
      "             47918   cluster dask-wor smomw122  R       1:44      1 neshcl203 \n",
      "             47919   cluster dask-wor smomw122  R       1:44      1 neshcl203 \n",
      "             47920   cluster dask-wor smomw122  R       1:44      1 neshcl203 \n",
      "             47921   cluster dask-wor smomw122  R       1:44      1 neshcl214 \n",
      "             47922   cluster dask-wor smomw122  R       1:44      1 neshcl214 \n",
      "             47923   cluster dask-wor smomw122  R       1:44      1 neshcl214 \n",
      "             47924   cluster dask-wor smomw122  R       1:44      1 neshcl216 \n",
      "             47925   cluster dask-wor smomw122  R       1:44      1 neshcl216 \n",
      "             47926   cluster dask-wor smomw122  R       1:44      1 neshcl216 \n",
      "             47927   cluster dask-wor smomw122  R       1:44      1 neshcl216 \n",
      "             47928   cluster dask-wor smomw122  R       1:44      1 neshcl222 \n",
      "             47929   cluster dask-wor smomw122  R       1:44      1 neshcl222 \n",
      "             47930   cluster dask-wor smomw122  R       1:44      1 neshcl222 \n",
      "             47931   cluster dask-wor smomw122  R       1:44      1 neshcl222 \n",
      "             47933   cluster dask-wor smomw122  R       1:44      1 neshcl323 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start a computation with disappearing workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 8 B </td> <td> 8 B </td></tr>\n",
       "    <tr><th> Shape </th><td> () </td> <td> () </td></tr>\n",
       "    <tr><th> Count </th><td> 63338 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<truediv, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pi = calculate_pi(\n",
    "    size_in_bytes=1_000_000_000_000, number_of_chunks=10_000\n",
    ")\n",
    "display(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: finalize-7463e029451ffcef396af73f3510904c>\n"
     ]
    }
   ],
   "source": [
    "pi = client.compute(pi)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will cancel job 47941\n",
      "will cancel job 47928\n",
      "will cancel job 47933\n",
      "will cancel job 47926\n",
      "will cancel job 47943\n",
      "will cancel job 47929\n",
      "will cancel job 47936\n",
      "will cancel job 47940\n"
     ]
    }
   ],
   "source": [
    "sleep(5)\n",
    "\n",
    "while not pi.done():\n",
    "    kill_random_preemptible_job()\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14160183008\n"
     ]
    }
   ],
   "source": [
    "print(pi.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened?\n",
    "\n",
    "The Dask scheduler keeps a suspiciousness counter for each task it manages.  Whenever a worker dies, all tasks that belong to the worker at the time of its death will have their suspiciousness increased by one. In doing so, the scheduler has no way of telling which exact task was responsible for the death of the worker and just flag all of them as bad.\n",
    "\n",
    "All tasks with suspiciousness `>= 3` (default) are considered bad and won't be rescheduled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dask more resilient\n",
    "\n",
    "We can increase the number of allowed failures.  Let's practically disable the threshold and re-do the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scheduler.allowed_failures = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Note that the above is internal API that we need to use to increase the number of allowed failures for now.  With the current Dask.distributed release that we can't, however, use with Dask jobqueue yet, this can be changed by changing the Dask configuration at runtime.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = calc_pi_mc(1e12, 500e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = client.compute(pi)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(5)\n",
    "\n",
    "while not pi.done():\n",
    "    kill_random_preemptible_job()\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
