{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask jobqueue example\n",
    "\n",
    "## What is Dask jobqueue? (<https://jobqueue.dask.org/>)\n",
    "\n",
    "* deploys Dask workers on typical HPC job queueing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo estimate with multiple Dask batch job workers\n",
    "\n",
    "We define a Dask jobqueue cluster with Dask workers that each have 8 CPUs and 48 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.distributed\n",
    "import dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "\n",
    "    # Dask worker size\n",
    "    cores=8, memory='48GB',\n",
    "    processes=1, # Dask workers per job\n",
    "    \n",
    "    # SLURM job script things\n",
    "    queue='cluster', walltime='00:15:00',\n",
    "    \n",
    "    # Dask worker network and temporary storage\n",
    "    interface='ib0', local_directory='$TMPDIR'\n",
    ")\n",
    "\n",
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:33939</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:33939' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a jobqueue cluster?\n",
    "The above is all we need to specify to run the computation on compute node Dask workers. \n",
    "Let's have a look at what's happening in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             55461   cluster dask-wor smomw122 PD       0:00      1 (None) \n",
      "             55371   cluster jupyterl smomw122  R      18:01      1 neshcl100 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p cluster\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --mem=45G\n",
      "#SBATCH -t 00:15:00\n",
      "\n",
      "/gxfs_home/geomar/smomw122/miniconda3/envs/dask_jobqueue_workshop/bin/python -m distributed.cli.dask_worker tcp://172.18.4.100:33939 --nthreads 8 --memory-limit 48.00GB --name dummy-name --nanny --death-timeout 60 --local-directory $TMPDIR --interface ib0 --protocol tcp://\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:33939</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:33939' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scale up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             55461   cluster dask-wor smomw122 PD       0:00      1 (None) \n",
      "             55462   cluster dask-wor smomw122 PD       0:00      1 (None) \n",
      "             55371   cluster jupyterl smomw122  R      18:02      1 neshcl100 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:33939</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:33939' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here everything is the same as with LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, dask.array\n",
    "\n",
    "def calculate_pi(size_in_bytes, number_of_chunks):\n",
    "    \n",
    "    \"\"\"Calculate pi using a Monte Carlo method.\"\"\"\n",
    "    \n",
    "    array_shape = (int(size_in_bytes / 8 / 2), 2)\n",
    "    chunk_size = (int(array_shape[0] / number_of_chunks), 2)\n",
    "    \n",
    "    # 2D random positions array using dask.array\n",
    "    xy = dask.array.random.uniform(\n",
    "        low=0.0, high=1.0, size=array_shape,\n",
    "        # specify chunk size, i.e. task number\n",
    "        chunks=chunk_size )\n",
    "  \n",
    "    xy_inside_circle = (xy ** 2).sum(axis=1) < 1 # boolean\n",
    "\n",
    "    pi = 4 * xy_inside_circle.sum() / xy_inside_circle.size\n",
    "    \n",
    "    # start Dask calculation\n",
    "    pi = pi.compute()\n",
    "\n",
    "    print(f\"\\nfrom {xy.nbytes / 1e9} GB randomly chosen positions\")\n",
    "    print(f\"   pi estimate: {pi}\")\n",
    "    print(f\"   pi error: {abs(pi - numpy.pi)}\\n\")\n",
    "    # display(xy)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 10.0 GB randomly chosen positions\n",
      "   pi estimate: 3.1416435008\n",
      "   pi error: 5.084721020676142e-05\n",
      "\n",
      "CPU times: user 219 ms, sys: 27.4 ms, total: 246 ms\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 100.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14162127552\n",
      "   pi error: 2.8621930206806923e-05\n",
      "\n",
      "CPU times: user 469 ms, sys: 56.2 ms, total: 525 ms\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=250) # 100 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14159954144\n",
      "   pi error: 6.88785020708238e-06\n",
      "\n",
      "CPU times: user 4.97 s, sys: 431 ms, total: 5.4 s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=2_000) # 1 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can easily scale down the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             55464   cluster dask-wor smomw122 CG       0:55      1 neshcl101 \n",
      "             55474   cluster dask-wor smomw122 PD       0:00      1 (Resources) \n",
      "             55475   cluster dask-wor smomw122 PD       0:00      1 (Priority) \n",
      "             55470   cluster dask-wor smomw122  R       0:18      1 neshcl213 \n",
      "             55471   cluster dask-wor smomw122  R       0:18      1 neshcl306 \n",
      "             55472   cluster dask-wor smomw122  R       0:18      1 neshcl322 \n",
      "             55473   cluster dask-wor smomw122  R       0:18      1 neshcl323 \n",
      "             55461   cluster dask-wor smomw122  R       0:55      1 neshcl251 \n",
      "             55462   cluster dask-wor smomw122  R       0:55      1 neshcl266 \n",
      "             55463   cluster dask-wor smomw122  R       0:55      1 neshcl100 \n",
      "             55465   cluster dask-wor smomw122  R       0:55      1 neshcl103 \n",
      "             55466   cluster dask-wor smomw122  R       0:55      1 neshcl253 \n",
      "             55467   cluster dask-wor smomw122  R       0:55      1 neshcl253 \n",
      "             55468   cluster dask-wor smomw122  R       0:55      1 neshcl253 \n",
      "             55371   cluster jupyterl smomw122  R      18:57      1 neshcl100 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we can scale up the cluster whenever needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             55462   cluster dask-wor smomw122 CG       0:55      1 neshcl266 \n",
      "             55463   cluster dask-wor smomw122 CG       0:55      1 neshcl100 \n",
      "             55464   cluster dask-wor smomw122 CG       0:55      1 neshcl101 \n",
      "             55468   cluster dask-wor smomw122 CG       0:55      1 neshcl253 \n",
      "             55474   cluster dask-wor smomw122 PD       0:00      1 (Resources) \n",
      "             55475   cluster dask-wor smomw122 PD       0:00      1 (Priority) \n",
      "             55470   cluster dask-wor smomw122  R       0:18      1 neshcl213 \n",
      "             55471   cluster dask-wor smomw122  R       0:18      1 neshcl306 \n",
      "             55472   cluster dask-wor smomw122  R       0:18      1 neshcl322 \n",
      "             55473   cluster dask-wor smomw122  R       0:18      1 neshcl323 \n",
      "             55461   cluster dask-wor smomw122  R       0:55      1 neshcl251 \n",
      "             55465   cluster dask-wor smomw122  R       0:55      1 neshcl103 \n",
      "             55466   cluster dask-wor smomw122  R       0:55      1 neshcl253 \n",
      "             55467   cluster dask-wor smomw122  R       0:55      1 neshcl253 \n",
      "             55371   cluster jupyterl smomw122  R      18:57      1 neshcl100 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:33939</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>64</li>\n",
       "  <li><b>Memory: </b>384.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:33939' processes=8 threads=64, memory=384.00 GB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=2_000) # 1 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=10_000_000_000_000, number_of_chunks=10_000) # 10 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, we could also adaptively scale the jobqueue cluster!\n",
    "\n",
    "Dask jobqueue is able to scale total worker number based on problem size. You can also specify a target duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x149d989fb5b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(\n",
    "    minimum_jobs=2, maximum_jobs=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 10.0 GB randomly chosen positions\n",
      "   pi estimate: 3.1415523008\n",
      "   pi error: 4.0352789793196564e-05\n",
      "\n",
      "CPU times: user 254 ms, sys: 7.25 ms, total: 261 ms\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141595556288\n",
      "   pi error: 2.902698206685983e-06\n",
      "\n",
      "CPU times: user 3.08 s, sys: 284 ms, total: 3.37 s\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=1_000) # 1 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=10_000_000_000_000, number_of_chunks=10_000) # 10 TB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
