{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask jobqueue example\n",
    "\n",
    "## What is Dask jobqueue? (<https://jobqueue.dask.org/>)\n",
    "\n",
    "* deploys Dask workers on typical HPC job queueing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo estimate with multiple Dask batch job workers\n",
    "\n",
    "We define a Dask jobqueue cluster with Dask workers that each have 8 CPUs and 48 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.distributed\n",
    "import dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "\n",
    "    # Dask worker size\n",
    "    cores=8, memory='48GB',\n",
    "    processes=1, # Dask workers per job\n",
    "    \n",
    "    # SLURM job script things\n",
    "    queue='cluster', walltime='00:15:00',\n",
    "    \n",
    "    # Dask worker network and temporary storage\n",
    "    interface='ib0', local_directory='$TMPDIR'\n",
    ")\n",
    "\n",
    "client = dask.distributed.Client(cluster)\n",
    "cluster.scale(jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:42503</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>48.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:42503' processes=1 threads=8, memory=48.00 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a jobqueue cluster?\n",
    "The above is all we need to specify to run the computation on compute node Dask workers. \n",
    "Let's have a look at what's happening in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             54643   cluster jupyterl smomw122  R      25:21      1 neshcl100 \n",
      "             54699   cluster dask-wor smomw122  R       0:37      1 neshcl229 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p cluster\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --mem=45G\n",
      "#SBATCH -t 00:15:00\n",
      "\n",
      "/gxfs_home/geomar/smomw122/miniconda3/envs/dask_jobqueue_workshop/bin/python -m distributed.cli.dask_worker tcp://172.18.4.100:42503 --nthreads 8 --memory-limit 48.00GB --name dummy-name --nanny --death-timeout 60 --local-directory $TMPDIR --interface ib0 --protocol tcp://\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:42503</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>48.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:42503' processes=1 threads=8, memory=48.00 GB>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scale up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             54643   cluster jupyterl smomw122  R      26:44      1 neshcl100 \n",
      "             54705   cluster dask-wor smomw122  R       0:28      1 neshcl251 \n",
      "             54706   cluster dask-wor smomw122  R       0:28      1 neshcl251 \n",
      "             54707   cluster dask-wor smomw122  R       0:28      1 neshcl251 \n",
      "             54708   cluster dask-wor smomw122  R       0:28      1 neshcl251 \n",
      "             54702   cluster dask-wor smomw122  R       0:59      1 neshcl229 \n",
      "             54703   cluster dask-wor smomw122  R       0:59      1 neshcl230 \n",
      "             54704   cluster dask-wor smomw122  R       0:59      1 neshcl230 \n",
      "             54699   cluster dask-wor smomw122  R       2:00      1 neshcl229 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:42503</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>64</li>\n",
       "  <li><b>Memory: </b>384.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:42503' processes=8 threads=64, memory=384.00 GB>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here everything is the same as with LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, dask.array\n",
    "\n",
    "def calculate_pi(size_in_bytes, number_of_chunks):\n",
    "    \n",
    "    \"\"\"Calculate pi using a Monte Carlo method.\"\"\"\n",
    "    \n",
    "    array_shape = (int(size_in_bytes / 8 / 2), 2)\n",
    "    chunk_size = (int(array_shape[0] / number_of_chunks), 2)\n",
    "    \n",
    "    # 2D random positions array using dask.array\n",
    "    xy = dask.array.random.uniform(\n",
    "        low=0.0, high=1.0, size=array_shape,\n",
    "        # specify chunk size, i.e. task number\n",
    "        chunks=chunk_size )\n",
    "  \n",
    "    xy_inside_circle = (xy ** 2).sum(axis=1) < 1 # boolean\n",
    "\n",
    "    pi = 4 * xy_inside_circle.sum() / xy_inside_circle.size\n",
    "    \n",
    "    # start Dask calculation\n",
    "    pi = pi.compute()\n",
    "\n",
    "    print(f\"\\nfrom {xy.nbytes / 1e9} GB randomly chosen positions\")\n",
    "    print(f\"   pi estimate: {pi}\")\n",
    "    print(f\"   pi error: {abs(pi - numpy.pi)}\\n\")\n",
    "    # display(xy)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 10.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14151968\n",
      "   pi error: 7.297358979307944e-05\n",
      "\n",
      "CPU times: user 746 ms, sys: 32.6 ms, total: 778 ms\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 100.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14155992512\n",
      "   pi error: 3.2728469792964177e-05\n",
      "\n",
      "CPU times: user 2 s, sys: 74.5 ms, total: 2.08 s\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=250) # 100 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141602444672\n",
      "   pi error: 9.791082206778157e-06\n",
      "\n",
      "CPU times: user 23.3 s, sys: 607 ms, total: 23.9 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=2_000) # 1 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can easily scale down the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             54643   cluster jupyterl smomw122  R      29:00      1 neshcl100 \n",
      "             54708   cluster dask-wor smomw122  R       2:44      1 neshcl251 \n",
      "             54699   cluster dask-wor smomw122  R       4:16      1 neshcl229 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we can scale up the cluster whenever needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "             54724   cluster dask-wor smomw122 PD       0:00      1 (Priority) \n",
      "             54643   cluster jupyterl smomw122  R      29:52      1 neshcl100 \n",
      "             54719   cluster dask-wor smomw122  R       0:05      1 neshcl253 \n",
      "             54720   cluster dask-wor smomw122  R       0:05      1 neshcl254 \n",
      "             54721   cluster dask-wor smomw122  R       0:05      1 neshcl254 \n",
      "             54722   cluster dask-wor smomw122  R       0:05      1 neshcl254 \n",
      "             54723   cluster dask-wor smomw122  R       0:05      1 neshcl254 \n",
      "             54711   cluster dask-wor smomw122  R       0:35      1 neshcl229 \n",
      "             54712   cluster dask-wor smomw122  R       0:35      1 neshcl230 \n",
      "             54713   cluster dask-wor smomw122  R       0:35      1 neshcl230 \n",
      "             54714   cluster dask-wor smomw122  R       0:35      1 neshcl251 \n",
      "             54715   cluster dask-wor smomw122  R       0:35      1 neshcl251 \n",
      "             54716   cluster dask-wor smomw122  R       0:35      1 neshcl251 \n",
      "             54717   cluster dask-wor smomw122  R       0:35      1 neshcl253 \n",
      "             54718   cluster dask-wor smomw122  R       0:35      1 neshcl253 \n",
      "             54708   cluster dask-wor smomw122  R       3:36      1 neshcl251 \n",
      "             54699   cluster dask-wor smomw122  R       5:08      1 neshcl229 \n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.100:42503</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.100:8787/status' target='_blank'>http://172.18.4.100:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>11</li>\n",
       "  <li><b>Cores: </b>88</li>\n",
       "  <li><b>Memory: </b>528.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.100:42503' processes=11 threads=88, memory=528.00 GB>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 100.0 GB randomly chosen positions\n",
      "   pi estimate: 3.14158721024\n",
      "   pi error: 5.443349793132768e-06\n",
      "\n",
      "CPU times: user 8.15 s, sys: 214 ms, total: 8.36 s\n",
      "Wall time: 8.5 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=100_000_000_000, number_of_chunks=2_000) # 1 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=10_000_000_000_000, number_of_chunks=10_000) # 10 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, we could also adaptively scale the jobqueue cluster!\n",
    "\n",
    "Dask jobqueue is able to scale total worker number based on problem size. You can also specify a target duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x151a280986a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(\n",
    "    minimum=2, maximum=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 10.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141622016\n",
      "   pi error: 2.93624102067902e-05\n",
      "\n",
      "CPU times: user 1.07 s, sys: 56 ms, total: 1.12 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=10_000_000_000, number_of_chunks=100) # 10 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from 1000.0 GB randomly chosen positions\n",
      "   pi estimate: 3.141587770816\n",
      "   pi error: 4.882773793291051e-06\n",
      "\n",
      "CPU times: user 21.2 s, sys: 506 ms, total: 21.7 s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%time pi = calculate_pi(size_in_bytes=1_000_000_000_000, number_of_chunks=1_000) # 1 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time pi = calculate_pi(size_in_bytes=10_000_000_000_000, number_of_chunks=10_000) # 10 TB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
